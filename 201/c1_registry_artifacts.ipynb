{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hhsvwitJxJla"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLWeJMdcQ3SF"
      },
      "outputs": [],
      "source": [
        "!pip install wandb torch pandas -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log in to W&B\n",
        "- You can explicitly login using `wandb login` or `wandb.login()` (See below)\n",
        "- Alternatively you can set environment variables. There are several env variables which you can set to change the behavior of W&B logging. The most important are:\n",
        "    - `WANDB_API_KEY` - find this in your \"Settings\" section under your profile\n",
        "    - `WANDB_BASE_URL` - this is the url of the W&B server\n",
        "- Find your API Token in \"Profile\" -> \"Setttings\" in the W&B App"
      ],
      "metadata": {
        "id": "sMA4lrKBRZha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "WANDB_ENTITY = 'smle-demo' #@param #Entity points to a team you are a part of!\n",
        "WANDB_PROJECT = \"wandb-intro-session\" #@param\n",
        "YOUR_NAME = \"timmy\" #We will use this for our filtering and grouping to make it easy for your to identify your runs in the project\n"
      ],
      "metadata": {
        "id": "nwvweTIVRSEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace WANDB_HOST with the C1 instance URL\n",
        "WANDB_HOST=\"<host>\" #@param\n",
        "wandb.login(host=WANDB_HOST)"
      ],
      "metadata": {
        "id": "XjNI1tdFRXWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artifacts\n",
        "\n",
        "Use W&B Artifacts to track and version data as the inputs and outputs of your W&B Runs. In addition to logging hyperparameters, metadata, and metrics to a run, you can use an artifact to log the dataset used to train the model as input and the resulting model checkpoints as outputs.\n"
      ],
      "metadata": {
        "id": "CMmSYNVIowQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this demo, we are going to go through the workflow of\n",
        "1. Creating a dataset\n",
        "2. Logging it to wandb\n",
        "3. Processing that dataset\n",
        "4. Logging the processed data to wandb\n",
        "5. Conducting model training\n",
        "6. Viewing the entire lineage of this process in the wandb UI"
      ],
      "metadata": {
        "id": "c-Fa78iOozcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Dataset\n",
        "Let's create some datasets that we can work with in this example."
      ],
      "metadata": {
        "id": "jDBUedUSo2rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "directory = \"dataset\"\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "file1, file2 = os.path.join(directory, \"file1.csv\"), os.path.join(directory, \"file2.csv\")\n",
        "\n",
        "def generate_dummy_data(num_samples):\n",
        "    data = [\n",
        "        np.random.normal(50, 10, num_samples),\n",
        "        np.random.randint(1, 100, num_samples),\n",
        "        np.random.choice(['A', 'B', 'C', 'D'], num_samples),\n",
        "        np.random.uniform(0.0, 1.0, num_samples)\n",
        "    ]\n",
        "    return zip(*data)\n",
        "\n",
        "def save_to_csv(file, data):\n",
        "    with open(file, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['feature1', 'feature2', 'feature3', 'feature4'])\n",
        "        writer.writerows(data)\n",
        "\n",
        "num_samples = 100\n",
        "save_to_csv(file1, generate_dummy_data(num_samples))\n",
        "save_to_csv(file2, generate_dummy_data(num_samples))"
      ],
      "metadata": {
        "id": "TeQpaVQ3o4Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general workflow for creating an Artifact is:\n",
        "\n",
        "1. Intialize a run.\n",
        "2. Create an Artifact.\n",
        "3. Add a any files, directories, or pointers to the new Artifact that you want to track and version.\n",
        "4. Log the artifact in the W&B platform."
      ],
      "metadata": {
        "id": "O8uxFNlZo5_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the [Artifacts Reference guide](https://www.google.com/url?q=https%3A%2F%2Fdocs.wandb.ai%2Fref%2Fpython%2Fartifact) for more information and other commonly used arguments, including how to store additional metadata.\n",
        "\n",
        "Each time the above `log_artifact` is executed, wandb will create a new version of the Artifact within Weights & Biases if the underlying data has changed."
      ],
      "metadata": {
        "id": "7e752M_ko7_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Versioning"
      ],
      "metadata": {
        "id": "i_ygNIzno99d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT, job_type='log_dataset')\n",
        "\n",
        "artifact = wandb.Artifact(f\"my_first_artifact_{YOUR_NAME}\", type=\"dataset\")\n",
        "# the below will add two individual files to the artifact.\n",
        "artifact.add_file(local_path=f\"{directory}/file1.csv\")\n",
        "artifact.add_file(local_path=f\"{directory}/file2.csv\")\n",
        "# or the below if you wanted to add the entire directory contents.\n",
        "artifact.add_dir(local_path=f\"{directory}\")\n",
        "# explictly log the artifact to Weights & Biases.\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "4pZpibs3o_pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the [Artifacts Reference guide](https://www.google.com/url?q=https%3A%2F%2Fdocs.wandb.ai%2Fref%2Fpython%2Fartifact) for more information and other commonly used arguments, including how to store additional metadata.\n",
        "\n",
        "Each time the above `log_artifact` is executed, wandb will create a new version of the Artifact within Weights & Biases if the underlying data has changed."
      ],
      "metadata": {
        "id": "alkZLUsUpAJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging this dataset artifact"
      ],
      "metadata": {
        "id": "Dxg3ipqUoBvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT, job_type='log_dataset')\n",
        "\n",
        "artifact = wandb.Artifact(f\"my_first_artifact_{YOUR_NAME}\", type=\"dataset\")\n",
        "# the below will add two individual files to the artifact.\n",
        "artifact.add_file(local_path=f\"{directory}/file1.csv\")\n",
        "artifact.add_file(local_path=f\"{directory}/file2.csv\")\n",
        "# or the below if you wanted to add the entire directory contents.\n",
        "artifact.add_dir(local_path=f\"{directory}\")\n",
        "# explictly log the artifact to Weights & Biases.\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "kTkSrwatn_yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing and Consuming the dataset Artifact"
      ],
      "metadata": {
        "id": "RJE5kHqxvluu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you want to use a specific version of an Artifact in a downstream task, you can specify the specific version you would like to use via either `v0`, `v1`, `v2` and so on, or via specific aliases you may have added. The latest alias always refers to the most recent version of the Artifact logged.\n",
        "\n",
        "The proceeding code snippet specifies that the W&B Run will use an artifact called my_first_artifact with the alias latest. We will take a step to preprocess our dataset and relog it to wandb, so we can see the lineage up until this point:"
      ],
      "metadata": {
        "id": "yF06r76Mvng4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT, job_type='process_dataset')\n",
        "artifact = run.use_artifact(artifact_or_name=f\"my_first_artifact_{YOUR_NAME}:latest\") # this creates a reference within Weights & Biases that this artifact was used by this run.\n",
        "path = artifact.download() # this downloads the artifact from Weights & Biases to your local system where the code is executing.\n",
        "\n",
        "print(f\"Data directory located at {path}\")"
      ],
      "metadata": {
        "id": "uUYpJ_S3uJzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_directory = \"processed_dataset\"\n",
        "os.makedirs(processed_directory, exist_ok=True)\n",
        "file1, file2 = os.path.join(directory, \"file1_processed.csv\"), os.path.join(directory, \"file2_processed.csv\")"
      ],
      "metadata": {
        "id": "J_KvYZZvvsLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Function to process and save the modified CSV data\n",
        "def process(input_file_path, output_file_path):\n",
        "    modified_data = []\n",
        "    with open(input_file_path, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        headers = next(reader)  # Skip headers\n",
        "        for row in reader:\n",
        "            # Example modification: Adjust feature1 by adding a constant\n",
        "            row[0] = str(float(row[0]) + 10)  # Modify feature1\n",
        "            modified_data.append(row)\n",
        "\n",
        "    # Save the modified data to the output path\n",
        "    with open(output_file_path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(headers)  # Write the headers back\n",
        "        writer.writerows(modified_data)\n",
        "\n",
        "# Apply modification to the CSV files\n",
        "process(os.path.join(path, \"file1.csv\"), os.path.join(processed_directory, \"file1_processed.csv\"))\n",
        "process(os.path.join(path, \"file2.csv\"), os.path.join(processed_directory, \"file2_processed.csv\"))"
      ],
      "metadata": {
        "id": "rEKjzvGVvtm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create a new artifact to store the modified data\n",
        "processed_artifact = wandb.Artifact(\n",
        "    f\"my_processed_artifact_{YOUR_NAME}\",\n",
        "    type=\"processed_dataset\"\n",
        ")\n",
        "\n",
        "# Add the modified CSV files to the new artifact\n",
        "processed_artifact.add_file(local_path=f\"{processed_directory}/file1_processed.csv\")\n",
        "processed_artifact.add_file(local_path=f\"{processed_directory}/file1_processed.csv\")\n",
        "\n",
        "# or the below if you wanted to add the entire directory contents.\n",
        "processed_artifact.add_dir(local_path=f\"{processed_directory}\")\n",
        "\n",
        "# Step 5: Log the processed artifact\n",
        "run.log_artifact(processed_artifact)\n",
        "\n",
        "# Finish the run\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "277EOvvCvvkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using our dataset during model training"
      ],
      "metadata": {
        "id": "ml6sdD_EvxTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "run = wandb.init(\n",
        "    entity = WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    group=YOUR_NAME,\n",
        "    job_type = \"training\",\n",
        "    config={'param': 42}\n",
        ")\n",
        "\n",
        "# Use our processed dataset in our training run\n",
        "# this creates a reference within Weights & Biases that this artifact was used by this run\n",
        "artifact = run.use_artifact(artifact_or_name=f\"my_processed_artifact_{YOUR_NAME}:latest\")\n",
        "\n",
        "#Save simple neural network model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleModel()\n",
        "\n",
        "# doing some dummy logging here\n",
        "for i in range(5):\n",
        "  wandb.log({\"acc\": random.random()})\n",
        "\n",
        "# Save the model and log to artifacts\n",
        "model_path = \"simple_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# Log the model as an artifact\n",
        "art = wandb.Artifact(name=f\"simple-model-{YOUR_NAME}\", type=f\"model\")\n",
        "art.add_file(model_path)\n",
        "run.log_artifact(art)\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "DSxzdRtmvyz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more information on ways to customize your Artifact download, including via the command line, see the [Download and Usage guide](https://docs.wandb.ai/guides/artifacts/download-and-use-an-artifact)."
      ],
      "metadata": {
        "id": "XTGbhhJKv1no"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update Artifact version metadata\n",
        "You can update the description, metadata, and alias of an artifact on the W&B platform during or outside a W&B Run.\n",
        "\n",
        "This example changes the description of the my_first_artifact artifact inside a run:"
      ],
      "metadata": {
        "id": "hhsvwitJxJla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(entity=WANDB_ENTITY, project=WANDB_PROJECT)\n",
        "artifact = run.use_artifact(artifact_or_name=f\"my_first_artifact_{YOUR_NAME}:latest\")\n",
        "artifact.description = \"This is an edited description.\"\n",
        "artifact.metadata = {\"source\": \"local disk\", \"internal data owner\": \"platform team\"}\n",
        "artifact.save()  # persists changes to an Artifact's properties\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "u3PjW8bTxK75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Snippet for Logging Reference Artifacts"
      ],
      "metadata": {
        "id": "ae-7epLkxM4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artifacts currently support the following URI schemes:\n",
        "\n",
        "* **http(s)://:** A path to a file accessible over HTTP. The artifact will track checksums in the form of etags and size metadata if the HTTP server supports the ETag and Content-Length response headers.\n",
        "* **s3://:** A path to an object or object prefix in S3. The artifact will track checksums and versioning information (if the bucket has object versioning enabled) for the referenced objects. Object prefixes are expanded to include the objects under the prefix, default up to 100,000 objects.\n",
        "* **gs://:** A path to an object or object prefix in GCS. The artifact will track checksums and versioning information (if the bucket has object versioning enabled) for the referenced objects. Object prefixes are expanded to include the objects under the prefix, default up to 100,000 objects.\n",
        "See below for an example of reference local files"
      ],
      "metadata": {
        "id": "qEnEZr91xOec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(entity=WANDB_ENTITY,\n",
        "                project=WANDB_PROJECT,\n",
        "                job_type=\"upload-references\")\n",
        "artifact = wandb.Artifact(name=f\"local-file-references_{YOUR_NAME}\", type=\"reference-dataset\")\n",
        "artifact.add_reference(\"file:///content/sample_data\", checksum=True)\n",
        "run.log_artifact(artifact)\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "hnkMIWi1xQJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Artifacts Time-to-live (TTL)**\n",
        "\n",
        "W&B Artifacts supports setting time-to-live policies on each version of an Artifact. The following examples show the use TTL policy in a common Artifact logging workflow. We'll cover:\n",
        "\n",
        "* Setting a TTL policy when creating an Artifact\n",
        "* Retroactively setting TTL for a specific Artifact aliases"
      ],
      "metadata": {
        "id": "84BE0iqkIzGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting TTL on New Artifacts\n",
        "Below we create two new Artifacts from the colab provided sample_data\n",
        "- mnist_test.csv\n",
        "- mnist_train_small.csv\n",
        "\n",
        "Upload them as artifacts files to artifact of type `mnist_dataset` and assign them a TTL"
      ],
      "metadata": {
        "id": "MzEXcqheI23B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "run = wandb.init(entity=WANDB_ENTITY,\n",
        "                project=WANDB_PROJECT,\n",
        "                job_type=\"raw-data\")\n",
        "\n",
        "raw_mnist_train = wandb.Artifact(\n",
        "    f\"mnist_train_small_{YOUR_NAME}\",\n",
        "    type=\"mnist_dataset\",\n",
        "    description=\"Small MNIST Training Set\"\n",
        ")\n",
        "\n",
        "raw_mnist_train.add_file(\"sample_data/mnist_train_small.csv\")\n",
        "raw_mnist_train.ttl = timedelta(days=10)\n",
        "run.log_artifact(raw_mnist_train, aliases=[\"small\", \"mnist\", \"train\"])\n",
        "\n",
        "raw_mnist_test = wandb.Artifact(\n",
        "    f\"mnist_test_small_{YOUR_NAME}\",\n",
        "    type=\"mnist_dataset\",\n",
        "    description=\"Small MNIST Test Set\"\n",
        ")\n",
        "\n",
        "raw_mnist_test.add_file(\"sample_data/mnist_test.csv\")\n",
        "raw_mnist_test.ttl = timedelta(days=10)\n",
        "run.log_artifact(raw_mnist_test, aliases=[\"small\", \"mnist\", \"test\"])\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "ASPVU_O3Iz6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full pipeline - data upload, model training, linking the best model to registry"
      ],
      "metadata": {
        "id": "szLTFEnJSY7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below pipeline includes:\n",
        "\n",
        "* Data Versioning: The Heart Disease dataset is split into training, validation, and test sets, each logged as a W&B artifact for easy tracking and reproducibility. The training dataset we linked to our dataset registry\n",
        "\n",
        "* Model Training: A neural network is trained on the training set, with performance monitored on the validation set. The best model version is saved and versioned as a W&B artifact which is then linked to our model registry\n",
        "\n",
        "* What It Showcases:\n",
        "How to use W&B for seamless data and model versioning.\n",
        "Best practices for tracking model performance during training and evaluation.\n",
        "Efficient and reproducible ML workflows in a production-ready environment."
      ],
      "metadata": {
        "id": "mIYTizxASW2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLLECTION_NAME = \"heart-disease\" #@param {type: \"string\"}"
      ],
      "metadata": {
        "id": "pt3293L4KDCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell downloads the UCI heart disease dataset as a csv file, as well as separates the data into training/val/test"
      ],
      "metadata": {
        "id": "GhWQhrHiZwb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Load the Heart Disease dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\",\n",
        "           \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "data = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Replace missing values ('?') with NaN and drop rows with NaN values\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "data = data.dropna().astype(float)\n",
        "\n",
        "# Convert target variable: 0 = no heart disease, 1 = presence of heart disease\n",
        "data['target'] = (data['target'] > 0).astype(int)\n",
        "\n",
        "# Shuffle the dataset to ensure random distribution\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Perform a train/validation/test split (60/20/20)\n",
        "train_size = int(0.6 * len(data))\n",
        "val_size = int(0.2 * len(data))\n",
        "test_size = len(data) - train_size - val_size\n",
        "\n",
        "train_data = data[:train_size]\n",
        "val_data = data[train_size:train_size + val_size]\n",
        "test_data = data[train_size + val_size:]\n",
        "\n",
        "# Save the entire dataset as a CSV file\n",
        "data.to_csv(\"heart_disease_full_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "fQxq5y0bZv4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is used to save a dataset to a file and log it as an artifact"
      ],
      "metadata": {
        "id": "5wQn0ZI0aGMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple function to save log dataset artifacts\n",
        "def save_and_log_dataset(data, filename, artifact_name, aliases):\n",
        "    # Save the dataset as a CSV file\n",
        "    data.to_csv(filename, index=False)\n",
        "\n",
        "    # Create and log the dataset artifact\n",
        "    dataset_artifact = wandb.Artifact(name=artifact_name, type='dataset')\n",
        "    dataset_artifact.add_file(filename)\n",
        "    wandb.log_artifact(dataset_artifact, aliases=aliases)\n",
        "\n",
        "    return dataset_artifact"
      ],
      "metadata": {
        "id": "hkVp7N56aFtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell is going to save our train, validation, and test datasets as artifacts, as well as link our training dataset to our Training Datasets registry"
      ],
      "metadata": {
        "id": "_E2wT4wXadQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload data to wandb\n",
        "\n",
        "run = wandb.init(entity=WANDB_ENTITY,\n",
        "                project=WANDB_PROJECT,\n",
        "                group = YOUR_NAME,\n",
        "                job_type=\"heart-disease-data-uploads\",\n",
        "                name = f\"heart_disease_data_uploads_{YOUR_NAME}\",\n",
        "                tags = [\"data-upload\"]\n",
        "                )\n",
        "\n",
        "# Save and log the entire dataset\n",
        "full_artifact = save_and_log_dataset(data, \"heart_disease_full_dataset.csv\", f'heart_disease_full_dataset_{YOUR_NAME}', [\"initial_commit\", \"complete_dataset\"])\n",
        "\n",
        "# Save and log the training dataset\n",
        "train_artifact = save_and_log_dataset(train_data, \"heart_disease_train_dataset.csv\", f'heart_disease_train_dataset_{YOUR_NAME}', [\"initial_commit\", \"train_split\"])\n",
        "\n",
        "# Save and log the validation dataset\n",
        "val_artifact = save_and_log_dataset(val_data, \"heart_disease_val_dataset.csv\", f'heart_disease_validation_dataset_{YOUR_NAME}', [\"initial_commit\", \"validation_split\"])\n",
        "\n",
        "# Save and log the test dataset\n",
        "test_artifact = save_and_log_dataset(test_data, \"heart_disease_test_dataset.csv\", f'heart_disease_test_dataset_{YOUR_NAME}', [\"initial_commit\", \"test_split\"])\n",
        "\n",
        "\n",
        "#Log all dataset to W&B tables for visual analysis\n",
        "wandb.log({f\"train_data_table_{YOUR_NAME}\": wandb.Table(dataframe=train_data),\n",
        "           f\"test_data_table_{YOUR_NAME}\": wandb.Table(dataframe=test_data),\n",
        "           f\"validation_data_table_{YOUR_NAME}\": wandb.Table(dataframe=val_data)})\n",
        "\n",
        "# Linking Training Dataset to collection in dataset registry\n",
        "target_path = f\"wandb-registry-dataset/{COLLECTION_NAME}\"\n",
        "\n",
        "run.link_artifact(\n",
        "  artifact=train_artifact,\n",
        "  target_path= target_path\n",
        ")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "Me0jTTJfRkBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell is going to pull the latest training dataset from our training dataset registry so we can start training on it.\n",
        "\n",
        "During training, we save our model checkpoints as artifacts, but we're going to promote our best model from our training to our model registry"
      ],
      "metadata": {
        "id": "_0PiEjluSuZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "eBubJF3sQkp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#simple function for loading artifacts from wandb\n",
        "def load_and_split_data(entity, project, artifact_name, your_name, split_name):\n",
        "\n",
        "    artifact_full_name = f'{entity}/{project}/{artifact_name}_{your_name}:latest'\n",
        "    artifact = wandb.use_artifact(artifact_full_name, type='dataset')\n",
        "    artifact_dir = artifact.download()#If you are using local version of artifact, you can simple utilize wandb.use_artifact() only instead of downloading to associated lineage to the artifact\n",
        "\n",
        "    data = pd.read_csv(f\"{artifact_dir}/heart_disease_{split_name}_dataset.csv\")\n",
        "\n",
        "    X = torch.tensor(data.drop(\"target\", axis=1).values, dtype=torch.float32)\n",
        "    y = torch.tensor(data[\"target\"].values, dtype=torch.float32)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Initialize training run\n",
        "run = wandb.init(entity=WANDB_ENTITY,\n",
        "                project=WANDB_PROJECT,\n",
        "                group = YOUR_NAME,\n",
        "                job_type=\"heart-disease-training\",\n",
        "                name = f\"heart_disease_training_validation_{YOUR_NAME}\"\n",
        "                )\n",
        "\n",
        "\n",
        "# Explicitly accessing Training data\n",
        "artifact = run.use_artifact('support_team/wandb-registry-Training Datasets/heart-disease:latest', type='dataset')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "data = pd.read_csv(f\"{artifact_dir}/heart_disease_train_dataset.csv\")\n",
        "\n",
        "X_train = torch.tensor(data.drop(\"target\", axis=1).values, dtype=torch.float32)\n",
        "y_train = torch.tensor(data[\"target\"].values, dtype=torch.float32)\n",
        "\n",
        "# Load validation data\n",
        "X_val, y_val = load_and_split_data(WANDB_ENTITY, WANDB_PROJECT, 'heart_disease_validation_dataset', YOUR_NAME, 'val')\n",
        "\n",
        "# Define a simple neural network model\n",
        "class HeartDiseaseModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(HeartDiseaseModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.bn3 = nn.BatchNorm1d(32)\n",
        "        self.fc4 = nn.Linear(32, 16)\n",
        "        self.fc5 = nn.Linear(16, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = torch.sigmoid(self.fc5(x))\n",
        "        return x\n",
        "\n",
        "model = HeartDiseaseModel(input_size=X_train.shape[1])\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_performance = float('inf')\n",
        "version = 1\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train).squeeze()\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate and log training accuracy\n",
        "    predictions = (outputs >= 0.5).float()\n",
        "    train_accuracy = (predictions == y_train).float().mean().item()\n",
        "\n",
        "    wandb.log({\"train/epoch\": epoch, \"train/train_loss\": loss.item(), \"train/train_accuracy\": train_accuracy})\n",
        "\n",
        "    # Evaluate the model on validation set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val).squeeze()\n",
        "        val_loss = criterion(val_outputs, y_val).item()\n",
        "\n",
        "        # Calculate and log validation accuracy\n",
        "        val_predictions = (val_outputs >= 0.5).float()\n",
        "        val_accuracy = (val_predictions == y_val).float().mean().item()\n",
        "\n",
        "        wandb.log({\"val/val_loss\": val_loss, \"val/val_accuracy\": val_accuracy})\n",
        "\n",
        "        if val_loss < best_performance:\n",
        "            best_performance = val_loss\n",
        "            model_path = f\"heart_disease_model_v{version}.pth\"\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            artifact = wandb.Artifact(name=f'heart_disease_model_{YOUR_NAME}', type='model')\n",
        "            artifact.add_file(model_path)\n",
        "            wandb.log_artifact(artifact, aliases=[f\"v{version}\", \"best\"])\n",
        "            version += 1\n",
        "\n",
        "# linking the best model to collection in model registry\n",
        "target_path = f\"wandb-registry-Model/{COLLECTION_NAME}\"\n",
        "\n",
        "# Giving it the production alias since this is our best model\n",
        "run.link_artifact(\n",
        "  artifact=artifact,\n",
        "  target_path= target_path,\n",
        "  aliases=[\"production\"]\n",
        ")\n",
        "\n",
        "run.finish()\n"
      ],
      "metadata": {
        "id": "9jebzVRnSuOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "pk4CSIzWYGKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}